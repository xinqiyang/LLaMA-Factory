model_name_or_path: THUDM/glm-4-9b-chat-1m
template: glm4
infer_backend: vllm
vllm_enforce_eager: true
vllm_maxlen: 2048
